{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNTk8qyVZQ1I9goQV0lka54",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Heresjohnnyi/Edius-Pro/blob/main/chronosage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pandas plotly scikit-learn numpy pyngrok fuzzywuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swsJZbxulw1Y",
        "outputId": "40815d93-ef28-49b4-f31a-1230aad79bf0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.41.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.11-py3-none-any.whl (25 kB)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fuzzywuzzy, watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed fuzzywuzzy-0.18.0 pydeck-0.9.1 pyngrok-7.2.11 streamlit-1.45.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile chrono_sage.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "import plotly.express as px\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import re\n",
        "import io\n",
        "import time\n",
        "from fuzzywuzzy import fuzz\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Streamlit configuration\n",
        "st.set_page_config(page_title=\"Chrono Sage\", layout=\"wide\")\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "        .main { background-color: #f5f7fa; }\n",
        "        .block-container { padding: 2rem; }\n",
        "        .stTextInput { background-color: #ffffff; border-radius: 5px; padding: 0.5em; }\n",
        "        .stButton { background-color: #4CAF50; color: white; }\n",
        "        .stSelectbox { background-color: #ffffff; }\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "st.title(\"ğŸ§  Chrono Sage - Time Series and Causal Inference engine\")\n",
        "st.markdown(\"**Explore your data with a chat-like interface, dynamic controls, and interactive plots! Upload a CSV and ask away.**\")\n",
        "\n",
        "# Initialize session state\n",
        "if 'chat_history' not in st.session_state:\n",
        "    st.session_state.chat_history = []\n",
        "if 'df_clean' not in st.session_state:\n",
        "    st.session_state.df_clean = None\n",
        "\n",
        "# Cache data loading and cleaning\n",
        "@st.cache_data\n",
        "def load_and_clean_data(file):\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading CSV: {e}\")\n",
        "        return None, 0\n",
        "    df_clean = df.copy()\n",
        "    for col in df_clean.columns:\n",
        "        if df_clean[col].dtype in ['float64', 'int64']:\n",
        "            imputer = SimpleImputer(strategy='median')\n",
        "            df_clean[col] = imputer.fit_transform(df_clean[[col]].values.reshape(-1, 1)).ravel()\n",
        "        else:\n",
        "            df_clean[col] = df_clean[col].fillna('Unknown')\n",
        "    elapsed_time = time.time() - start_time\n",
        "    return df_clean, elapsed_time\n",
        "\n",
        "# Helper functions\n",
        "def fuzzy_match_column(column, columns, threshold=80):\n",
        "    for col in columns:\n",
        "        if fuzz.partial_ratio(column.lower(), col.lower()) >= threshold:\n",
        "            return col\n",
        "    return None\n",
        "\n",
        "def extract_columns_from_prompt(prompt, columns):\n",
        "    words = prompt.lower().split()\n",
        "    matched_columns = []\n",
        "    for word in words:\n",
        "        matched_col = fuzzy_match_column(word, columns)\n",
        "        if matched_col and matched_col not in matched_columns:\n",
        "            matched_columns.append(matched_col)\n",
        "    return matched_columns\n",
        "\n",
        "def ineligible_error(function):\n",
        "    return f\"The dataset you provided is ineligible or not fit for performing {function}\"\n",
        "\n",
        "# Analysis functions\n",
        "def handle_summary(df):\n",
        "    start_time = time.time()\n",
        "    if df.empty:\n",
        "        return ineligible_error(\"summary\"), 0\n",
        "    st.subheader(\"ğŸ“Š Summary Statistics\")\n",
        "    st.dataframe(df.describe(include='all'))\n",
        "    elapsed_time = time.time() - start_time\n",
        "    return True, elapsed_time\n",
        "\n",
        "def handle_missing_values(df, column=None):\n",
        "    start_time = time.time()\n",
        "    if df.empty:\n",
        "        st.subheader(\"ğŸ©¶ï¿½ Missing Value Report\")\n",
        "        if column:\n",
        "            st.write(f\"Missing values in {column}: {df[column].isnull().sum()}\")\n",
        "        else:\n",
        "            st.write(df.isnull().sum())\n",
        "    elapsed_time = time.time() - start_time\n",
        "    return True, elapsed_time\n",
        "\n",
        "def handle_simulation(df, col=None, action=\"increase\", value=10.0, change_type=\"percent\", years=1, filters=None):\n",
        "    start_time = time.time()\n",
        "    valid_simulation = False\n",
        "    df_sim = df.copy()\n",
        "\n",
        "    if not col or col not in df.columns:\n",
        "        st.error(f\"Column '{col}' not found. Available: {list(df.columns)}\")\n",
        "        return ineligible_error(\"simulation\"), 0\n",
        "    if df_sim[col].dtype not in ['float64', 'int64']:\n",
        "        st.warning(f\"Column '{col}' must be numeric.\")\n",
        "        return ineligible_error(\"simulation\"), 0\n",
        "\n",
        "    temp_df = df_sim.copy()\n",
        "    if filters:\n",
        "        for filter_col, filter_val in filters.items():\n",
        "            if filter_col not in df.columns:\n",
        "                st.warning(f\"Filter column '{filter_col}' not found.\")\n",
        "                continue\n",
        "            try:\n",
        "                filter_val = float(filter_val) if df[filter_col].dtype in ['float64', 'int64'] else filter_val\n",
        "                temp_df = temp_df[temp_df[filter_col] == filter_val]\n",
        "            except ValueError:\n",
        "                st.warning(f\"Invalid filter value '{filter_val}' for '{filter_col}'.\")\n",
        "                continue\n",
        "        if temp_df.empty:\n",
        "            st.warning(\"No data matches filter conditions.\")\n",
        "            return ineligible_error(\"simulation\"), time.time() - start_time\n",
        "        df_sim = temp_df\n",
        "\n",
        "    for _ in range(years):\n",
        "        if change_type == \"percent\":\n",
        "            factor = (1 + value / 100) if action == \"increase\" else (1 - value / 100)\n",
        "            df_sim[col] = df_sim[col] * factor\n",
        "        else:\n",
        "            df_sim[col] = df_sim[col] + value if action == \"increase\" else df_sim[col] - value\n",
        "\n",
        "    st.write(f\"Simulated '{col}' {action}d by {value} {change_type} {'annually for ' + str(years) + ' years' if years > 1 else ''}\")\n",
        "    st.dataframe(df_sim[[col]].head(10))\n",
        "    fig = px.histogram(df_sim, x=col, title=f\"{col} after {action} by {value} {change_type}\", hover_data=df_sim.columns)\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "    valid_simulation = True\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    if not valid_simulation:\n",
        "        return ineligible_error(\"what-if simulation\"), elapsed_time\n",
        "    return True, elapsed_time\n",
        "\n",
        "def handle_causal_analysis(df, cause=None, effect=None, confounder=None):\n",
        "    start_time = time.time()\n",
        "    st.warning(\"Correlation does not imply causation. Results assume no unobserved confounders.\")\n",
        "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "    if len(numeric_cols) > 1:\n",
        "        fig = px.imshow(df[numeric_cols].corr(), text_auto=True, title=\"Correlation Matrix\", color_continuous_scale='Viridis')\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "    if not cause or not effect or cause not in df.columns or effect not in df.columns:\n",
        "        st.warning(f\"Invalid columns: '{cause}' or '{effect}'. Available: {list(df.columns)}\")\n",
        "        return ineligible_error(\"causal analysis\"), time.time() - start_time\n",
        "    if df[cause].dtype not in ['float64', 'int64'] or df[effect].dtype not in ['float64', 'int64']:\n",
        "        st.warning(f\"'{cause}' and '{effect}' must be numeric.\")\n",
        "        return ineligible_error(\"causal analysis\"), time.time() - start_time\n",
        "\n",
        "    if confounder and confounder in df.columns:\n",
        "        st.write(f\"Propensity Score Matching: Effect of {cause} on {effect} controlling for {confounder}\")\n",
        "        X_conf = df[[confounder]].values if df[confounder].dtype in ['float64', 'int64'] else pd.get_dummies(df[confounder], drop_first=True).values\n",
        "        scaler = StandardScaler()\n",
        "        X_conf_scaled = scaler.fit_transform(X_conf)\n",
        "\n",
        "        median_cause = df[cause].median()\n",
        "        df['treatment'] = (df[cause] > median_cause).astype(int)\n",
        "        treated = df[df['treatment'] == 1]\n",
        "        control = df[df['treatment'] == 0]\n",
        "\n",
        "        if len(treated) < 2 or len(control) < 2:\n",
        "            st.warning(f\"Insufficient data: treated={len(treated)}, control={len(control)}\")\n",
        "            return ineligible_error(\"propensity score matching\"), time.time() - start_time\n",
        "\n",
        "        with st.spinner(\"Running PSM...\"):\n",
        "            nn = NearestNeighbors(n_neighbors=1, n_jobs=-1)\n",
        "            nn.fit(X_conf_scaled[control.index])\n",
        "            distances, indices = nn.kneighbors(X_conf_scaled[treated.index])\n",
        "            matched_control = control.iloc[indices.flatten()]\n",
        "\n",
        "        ate = treated[effect].mean() - matched_control[effect].mean()\n",
        "        st.write(f\"ATE of {cause} on {effect}: {ate:.4f}\")\n",
        "        fig = px.box(pd.concat([treated[[effect]].assign(Group='Treated'), matched_control[[effect]].assign(Group='Control')]),\n",
        "                     x='Group', y=effect, title=f\"{effect}: Treated vs Matched Control\", hover_data=[effect])\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "    else:\n",
        "        st.write(f\"Linear Regression: {effect} ~ {cause}\")\n",
        "        X = df[[cause]].values\n",
        "        y = df[effect].values\n",
        "        model = LinearRegression()\n",
        "        model.fit(X, y)\n",
        "        st.write(f\"Coefficient: {model.coef_[0]:.4f}, Intercept: {model.intercept_:.4f}\")\n",
        "        fig = px.scatter(df, x=cause, y=effect, trendline=\"ols\", title=f\"Regression: {effect} vs {cause}\", hover_data=df.columns)\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    return True, elapsed_time\n",
        "\n",
        "def handle_plot(df, x_col=None, y_col=None):\n",
        "    start_time = time.time()\n",
        "    if not x_col or not y_col or x_col not in df.columns or y_col not in df.columns:\n",
        "        st.warning(f\"Columns '{x_col}' or '{y_col}' not found. Available: {list(df.columns)}\")\n",
        "        return ineligible_error(\"plotting\"), time.time() - start_time\n",
        "\n",
        "    st.subheader(f\"ğŸ“ˆ {y_col} vs {x_col}\")\n",
        "    if df[x_col].dtype in ['float64', 'int64'] and df[y_col].dtype in ['float64', 'int64']:\n",
        "        fig = px.scatter(df, x=x_col, y=y_col, title=f\"{y_col} vs {x_col}\", hover_data=df.columns)\n",
        "    else:\n",
        "        fig = px.box(df, x=x_col, y=y_col, title=f\"{y_col} vs {x_col}\", hover_data=df.columns)\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    return True, elapsed_time\n",
        "\n",
        "# Sidebar for analysis selection\n",
        "st.sidebar.header(\"ğŸ› ï¸ Analysis Options\")\n",
        "analysis_type = st.sidebar.selectbox(\n",
        "    \"Choose Analysis Type\",\n",
        "    [\"Summary\", \"Missing Values\", \"What-If Simulation\", \"Causal Analysis\", \"Plot\"],\n",
        "    help=\"Select the type of analysis to perform on your data.\"\n",
        ")\n",
        "\n",
        "# File uploader\n",
        "uploaded_file = st.file_uploader(\"ğŸ“ Upload CSV\", type=\"csv\", help=\"Upload a CSV file to analyze. Try 'chrono_sage_friendly.csv'!\")\n",
        "\n",
        "if uploaded_file:\n",
        "    with st.spinner(\"Loading data...\"):\n",
        "        progress_bar = st.progress(0)\n",
        "        st.session_state.df_clean, load_time = load_and_clean_data(uploaded_file)\n",
        "        progress_bar.progress(100)\n",
        "    if st.session_state.df_clean is None:\n",
        "        st.stop()\n",
        "\n",
        "    df_clean = st.session_state.df_clean\n",
        "    st.write(f\"Data loading and cleaning took {load_time:.2f} seconds\")\n",
        "    with st.expander(\"ğŸ§¾ Preview Data\", expanded=False):\n",
        "        st.dataframe(df_clean.head(10))\n",
        "\n",
        "    buffer = io.StringIO()\n",
        "    df_clean.to_csv(buffer, index=False)\n",
        "    st.download_button(\"Download Cleaned Data\", buffer.getvalue(), \"cleaned_data.csv\", help=\"Download the cleaned dataset.\")\n",
        "\n",
        "    columns = df_clean.columns.tolist()\n",
        "    numeric_cols = df_clean.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "    categorical_cols = df_clean.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "    # Dynamic inputs based on analysis type\n",
        "    if analysis_type == \"Summary\":\n",
        "        if st.button(\"Run Summary\", help=\"Generate summary statistics for all columns.\"):\n",
        "            with st.spinner(\"Generating summary...\"):\n",
        "                success, elapsed_time = handle_summary(df_clean)\n",
        "                st.write(f\"Analysis took {elapsed_time:.2f} seconds\")\n",
        "                st.session_state.chat_history.append((\"Summary\", \"Summary statistics generated.\"))\n",
        "\n",
        "    elif analysis_type == \"Missing Values\":\n",
        "        col = st.selectbox(\"Select Column (Optional)\", [\"All Columns\"] + columns, help=\"Choose a specific column or all for missing value report.\")\n",
        "        if st.button(\"Check Missing Values\", help=\"Show missing value counts.\"):\n",
        "            with st.spinner(\"Checking missing values...\"):\n",
        "                success, elapsed_time = handle_missing_values(df_clean, col if col != \"All Columns\" else None)\n",
        "                st.write(f\"Analysis took {elapsed_time:.2f} seconds\")\n",
        "                st.session_state.chat_history.append((\"Missing Values\", f\"Checked missing values for {col}.\"))\n",
        "\n",
        "    elif analysis_type == \"What-If Simulation\":\n",
        "        st.subheader(\"What-If Simulation\")\n",
        "        col = st.selectbox(\"Select Column to Modify\", numeric_cols, help=\"Choose a numeric column to simulate changes (e.g., discounted_price).\")\n",
        "        action = st.radio(\"Action\", [\"Increase\", \"Decrease\"], help=\"Increase or decrease the column values.\")\n",
        "        change_type = st.radio(\"Change Type\", [\"Percent\", \"Fixed\"], help=\"Apply change as percentage or fixed amount.\")\n",
        "        value = st.slider(\"Change Value\", 0.0, 100.0, 10.0, help=\"Amount to change (e.g., 10 for 10% or 10 units).\")\n",
        "        years = st.slider(\"Years (for Annual Change)\", 1, 5, 1, help=\"Number of years for annual compounding.\")\n",
        "        filter_cols = st.multiselect(\"Filter Columns\", columns, help=\"Select columns to filter data (e.g., category, region).\")\n",
        "        filters = {}\n",
        "        for filter_col in filter_cols:\n",
        "            unique_vals = df_clean[filter_col].unique().tolist()\n",
        "            filter_val = st.selectbox(f\"Value for {filter_col}\", unique_vals, key=filter_col)\n",
        "            filters[filter_col] = filter_val\n",
        "\n",
        "        if st.button(\"Run Simulation\", help=\"Run the what-if simulation with selected parameters.\"):\n",
        "            with st.spinner(\"Running simulation...\"):\n",
        "                progress_bar = st.progress(0)\n",
        "                success, elapsed_time = handle_simulation(df_clean, col, action.lower(), value, change_type.lower(), years, filters)\n",
        "                progress_bar.progress(100)\n",
        "                st.write(f\"Analysis took {elapsed_time:.2f} seconds\")\n",
        "                st.session_state.chat_history.append((\"What-If\", f\"Simulated {action.lower()} {col} by {value} {change_type.lower()}.\"))\n",
        "\n",
        "    elif analysis_type == \"Causal Analysis\":\n",
        "        st.subheader(\"Causal Analysis\")\n",
        "        cause = st.selectbox(\"Cause Column\", numeric_cols, help=\"Select the cause variable (e.g., discounted_price).\")\n",
        "        effect = st.selectbox(\"Effect Column\", numeric_cols, help=\"Select the effect variable (e.g., rating).\")\n",
        "        confounder = st.selectbox(\"Confounder Column (Optional)\", [\"None\"] + columns, help=\"Choose a confounder (e.g., category).\")\n",
        "        if st.button(\"Run Causal Analysis\", help=\"Estimate causal effect with PSM or regression.\"):\n",
        "            with st.spinner(\"Running causal analysis...\"):\n",
        "                progress_bar = st.progress(0)\n",
        "                success, elapsed_time = handle_causal_analysis(df_clean, cause, effect, None if confounder == \"None\" else confounder)\n",
        "                progress_bar.progress(100)\n",
        "                st.write(f\"Analysis took {elapsed_time:.2f} seconds\")\n",
        "                st.session_state.chat_history.append((\"Causal\", f\"Analyzed effect of {cause} on {effect}.\"))\n",
        "\n",
        "    elif analysis_type == \"Plot\":\n",
        "        st.subheader(\"Plot Data\")\n",
        "        x_col = st.selectbox(\"X-Axis Column\", columns, help=\"Choose column for X-axis (e.g., discounted_price).\")\n",
        "        y_col = st.selectbox(\"Y-Axis Column\", columns, help=\"Choose column for Y-axis (e.g., rating).\")\n",
        "        if st.button(\"Generate Plot\", help=\"Create an interactive scatter or box plot.\"):\n",
        "            with st.spinner(\"Generating plot...\"):\n",
        "                success, elapsed_time = handle_plot(df_clean, x_col, y_col)\n",
        "                st.write(f\"Analysis took {elapsed_time:.2f} seconds\")\n",
        "                st.session_state.chat_history.append((\"Plot\", f\"Plotted {y_col} vs {x_col}.\"))\n",
        "\n",
        "    # Chat-like interface\n",
        "    st.subheader(\"ğŸ’¬ Ask a Question\")\n",
        "    prompt_suggestions = [\n",
        "        \"Summarize data\",\n",
        "        \"Show missing values\",\n",
        "        \"What if discounted_price increased by 10 percent where category = Electronics\",\n",
        "        \"Causal effect of price on sales with region as confounder\",\n",
        "        \"Plot discounted_price vs rating\"\n",
        "    ]\n",
        "    prompt = st.selectbox(\"Try a Prompt\", [\"Type your own...\"] + prompt_suggestions, help=\"Select or type a query.\")\n",
        "    if prompt == \"Type your own...\":\n",
        "        prompt = st.text_input(\"Enter your question\", placeholder=\"e.g., What if sales increased by 10% where region = West\", help=\"Ask anything about your data!\")\n",
        "\n",
        "    if st.button(\"Submit Query\", help=\"Run the custom query.\"):\n",
        "        if prompt and prompt != \"Type your own...\":\n",
        "            st.session_state.chat_history.append((\"User\", prompt))\n",
        "            prompt_lower = prompt.lower()\n",
        "            with st.spinner(\"Processing query...\"):\n",
        "                progress_bar = st.progress(0)\n",
        "                success = False\n",
        "                elapsed_time = 0\n",
        "\n",
        "                if any(keyword in prompt_lower for keyword in ['summary', 'describe']):\n",
        "                    success, elapsed_time = handle_summary(df_clean)\n",
        "                elif any(keyword in prompt_lower for keyword in ['missing', 'null']):\n",
        "                    success, elapsed_time = handle_missing_values(df_clean)\n",
        "                elif 'what if' in prompt_lower:\n",
        "                    # Parse prompt manually for demo; use sidebar for structured input\n",
        "                    pattern = r'(?P<column>\\w+)\\s*(?P<action>increased|decreased)\\s*by\\s*(?P<value>\\d+\\.?\\d*)\\s*(?P<type>percent|fixed)(?:\\s*annually\\s*for\\s*(?P<years>\\d+)\\s*years)?(?:\\s*(?P<filter>where\\s+[\\w\\s=]+))?'\n",
        "                    match = re.search(pattern, prompt_lower)\n",
        "                    if match:\n",
        "                        try:\n",
        "                            groups = match.groupdict()\n",
        "                            col = fuzzy_match_column(groups['column'], columns)\n",
        "                            action = groups['action']\n",
        "                            value = float(groups['value'])\n",
        "                            change_type = groups['type']\n",
        "                            years = int(groups['years']) if groups['years'] else 1\n",
        "                            filters = {}\n",
        "                            if groups['filter']:\n",
        "                                conditions = re.findall(r'(\\w+)\\s*=\\s*([^ ]+)', groups['filter'])\n",
        "                                for filter_col, filter_val in conditions:\n",
        "                                    filter_col = fuzzy_match_column(filter_col, columns)\n",
        "                                    if filter_col:\n",
        "                                        filters[filter_col] = filter_val\n",
        "                            success, elapsed_time = handle_simulation(df_clean, col, action, value, change_type, years, filters)\n",
        "                        except ValueError:\n",
        "                            st.error(\"Invalid prompt format. Try: 'What if sales increased by 10% where region = West'\")\n",
        "                    else:\n",
        "                        st.error(ineligible_error(\"what-if simulation\"))\n",
        "                elif any(keyword in prompt_lower for keyword in ['causal', 'correlation', 'effect of']):\n",
        "                    match = re.search(r'effect of\\s+(\\w+)\\s+on\\s+(\\w+)(\\s+with\\s+(\\w+)\\s+as\\s+confounder)?', prompt_lower)\n",
        "                    if match:\n",
        "                        cause = fuzzy_match_column(match.group(1), columns)\n",
        "                        effect = fuzzy_match_column(match.group(2), columns)\n",
        "                        confounder = fuzzy_match_column(match.group(4), columns) if match.group(4) else None\n",
        "                        success, elapsed_time = handle_causal_analysis(df_clean, cause, effect, confounder)\n",
        "                    else:\n",
        "                        st.error(ineligible_error(\"causal analysis\"))\n",
        "                elif any(keyword in prompt_lower for keyword in ['plot', 'chart', 'graph']):\n",
        "                    selected = extract_columns_from_prompt(prompt, columns)\n",
        "                    if len(selected) >= 2:\n",
        "                        success, elapsed_time = handle_plot(df_clean, selected[0], selected[1])\n",
        "                    else:\n",
        "                        st.error(\"Need two columns for plotting. Try: 'plot discounted_price vs rating'\")\n",
        "                else:\n",
        "                    st.error(\"Unknown request. Try suggested prompts or use the sidebar.\")\n",
        "\n",
        "                progress_bar.progress(100)\n",
        "                st.write(f\"Analysis took {elapsed_time:.2f} seconds\")\n",
        "                if success:\n",
        "                    st.session_state.chat_history.append((\"Chrono Sage\", \"Analysis completed.\"))\n",
        "\n",
        "    # Display chat history\n",
        "    with st.expander(\"ğŸ’¬ Chat History\", expanded=True):\n",
        "        for sender, message in st.session_state.chat_history[-5:]:  # Show last 5 messages\n",
        "            st.write(f\"**{sender}:** {message}\")\n",
        "\n",
        "else:\n",
        "    st.info(\"Upload a CSV to start exploring! Try 'chrono_sage_friendly.csv' for a demo.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U85n9Pcil9Tk",
        "outputId": "acd175c9-4f14-4a51-e259-cf06fbba61b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting chrono_sage.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "!ngrok authtoken 2y7RjHikhB7yVj6BRRuXaG8MD4D_6TPAznn1x9he6NB5dJh6u\n",
        "get_ipython().system_raw(\"streamlit run chrono_sage.py &\")\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Streamlit app is running at: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le4bSSD_xc57",
        "outputId": "388cb494-b3df-47aa-df02-c0a6461cb2c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Streamlit app is running at: NgrokTunnel: \"https://8243-34-126-161-203.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}